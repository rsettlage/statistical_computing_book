{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Monte Carlo Methods\n",
    "\n",
    "### References\n",
    "\n",
    "[Beginning Bayesian Statistics](https://pubs.er.usgs.gov/publication/70204463)\n",
    "\n",
    "[Hamiltonian Monte Carlo in Python](https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/)\n",
    "\n",
    "[Betancourt HMC - Best introduction to HMC](https://www.youtube.com/watch?v=VnNdhsm0rJQ)\n",
    "\n",
    "[NUTS paper](http://arxiv.org/abs/1111.4246)\n",
    "\n",
    "[HMC Tuning by Colin Caroll](https://colcarroll.github.io/hmc_tuning_talk/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building blocks\n",
    "\n",
    "\n",
    "#### Random Walks\n",
    "\n",
    "\n",
    "#### Why does this work?\n",
    "\n",
    "#### Proposal distribution\n",
    "An easy to sample distribution such as a Gaussian distribution $q(x)$ such that \n",
    "\n",
    "$q(x_{i+1} | x_{i}) \\approx N(\\mu, \\sigma)$\n",
    "\n",
    "#### Foundation of Bayesian Inference\n",
    "\n",
    "1. Obtain the data and inspect it for a high-level understanding of the distribution of the data and the outliers\n",
    "2. Define a reasonable prior for the data based on (1) and your understanding of the problem\n",
    "3. Define a likelihood distribution for the data and obtain the likelihood of the data given this likelihood distribution\n",
    "4. Obtain the posterior distribution using (2) and (3) by applying the Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Metropolis Algorithm\n",
    "\n",
    "We start off by modeling a discrete number of events using a Poisson distribution shown below. \n",
    "\n",
    "$f(x) = e^{-\\mu} \\mu^x / x!$\n",
    "\n",
    "The mean rate is represented by Î¼ and x is positive integer that represents the number of events that can happen. If you recall from the discussion of the binomial distribution, that can also be used to model the probability of the number of successes out of 'n' trials. The Poisson distribution is a special case of this binomial distribution and is used when the trials far exceed the number of successes.\n",
    "\n",
    "If our observed data has a Poisson likelihood distribution, using a Gamma prior for $\\mu$ results in a Gamma posterior distribution. \n",
    "\n",
    "#### Outline of the Metropolis algorithm\n",
    "*What do we want to compute?*\n",
    "\n",
    "To estimate a distribution of a parameter $\\mu$\n",
    "\n",
    "*What do we have available?*\n",
    "\n",
    "Observed data\n",
    "\n",
    "*How do we do it?*\n",
    "\n",
    "1. Start with a parameter sample $\\mu_{current}$ that is drawn from a distribution\n",
    "2. Draw a second parameter sample $\\mu_{proposed}$ from a proposal distribution\n",
    "3. Compute the likelihood of the data for both the parameters\n",
    "4. Compute the prior probability density of both the parameters\n",
    "5. Compute the posterior probability density of both parameters by multiplying the prior and the likelihood from (3) and (4)\n",
    "6. Select one from the posterior probability density computed above using a rule and save the selected one as $\\mu_{current}$ \n",
    "7. Repeat steps (2) to (7) till a large number of parameters have been drawn (usually around 5000, but this really depends on the problem)\n",
    "8. Compute the distribution of the parameter $\\mu$ by plotting a histogram of the saved sampled parameter $\\mu_{current}$ in step (6)\n",
    "\n",
    "#### The details\n",
    "\n",
    "1. Propose a single plausible value for our parameter $\\mu$. This is $\\mu_{current}$ from the previous section. This is also called the current value. Let us assume that this is 7.5 for now.\n",
    "\n",
    "2. Compute the prior probability density of getting 7.5. We stated earlier in our example that we have a Gamma prior distribution for our parameter $\\mu$.\n",
    "\n",
    "   $Gamma(x=7.5, \\alpha, \\beta) = \\beta^{\\alpha} x^{\\alpha - 1} e^{-\\beta x} / \\gamma(\\alpha) = \\beta^{\\alpha} 7.5^{\\alpha - 1} e^{-\\beta 7.5} / \\gamma(\\alpha)$\n",
    "\n",
    "3. Compute the likelihood of the data given the parameter value of 7.5. The likelihood distribution was a Poisson distribution in our example\n",
    "\n",
    "   $Poisson(x, mu=7.5) = e^{-\\mu} \\mu^x / x! = e^{-7.5} 7.5^x / x!$\n",
    "\n",
    "4. Compute the posterior density from (2) and (3), we skip the denominator here since we are only going to make comparisons and the denominator is a constant.\n",
    "\n",
    "   Posterior density $\\propto$ Prior $\\cdot$ likelihood \n",
    "\n",
    "5. Propose a second value for $\\mu$, called $\\mu_{proposed}$, which is drawn from a distribution called a proposal distribution centered on $mu_{current}$. This value is called the proposed value. For the Metropolis algorithm, it has to be a symmetrical distribution. We will use a normal distribution for this example and set the mean of this proposal distribution to be the current value of $\\mu$. The standard deviation is a hyperparameter called the tuning parameter. Let us assume that we draw a value of 8.5.\n",
    "\n",
    "6. Compute the prior, likelihood and the posterior for this proposed value of $\\mu$ as we did in step (2), (3) and (4).\n",
    "\n",
    "7. Select one value from the current and the proposed value with the following two steps (this step is where the Metropolis algorithm differs from the Metropolis-Hastings algorithm)  \n",
    "\n",
    "   a. Compute the probability of moving to the proposed value as\n",
    "      $p_{move} = min( \\dfrac{P(\\mu_{proposed} | data)}{P(\\mu_{current} | data)}, 1)$\n",
    "\n",
    "      Here $p_{move}$ is the minimum of the values given by the ratio of the probabilities and the number 1. This caps the probability $p_{move}$ at 1 if the ratio happens to be greater than 1. $P_{move}$ is also referred to as the transition kernel.\n",
    "\n",
    "   b. Draw a sample from a uniform distribution U(0,1). If $p_{move}$ from (a) above is greater than this number drawn from the uniform distribution, we accept the proposed value $\\mu_{proposed}$. What this means is that if the posterior density of the proposed parameter value is greater than the posterior density of the current parameter value, then we move to the proposed value otherwise we probabilistically accept the proposed value based on the value of $p_{move}$ and the randomly drawn value from the uniform distribution.\n",
    "\n",
    "8. If we moved to the proposed value, save the current value to an array and then update the current value with the proposed value. In the next iteration, the current value $\\mu^{i+1}_{current}$ will be this accepted proposed value $\\mu^{i}_{proposed}$.\n",
    "\n",
    "9. Repeat steps (2) to (8) thousands of times and plot the histogram of the accepted values, i.e. the array of current values $\\mu_{current}$.\n",
    "   \n",
    "\n",
    "#### Traceplot \n",
    "\n",
    "The sequence of accepted values from the proposed values that is plotted over each draw. If a proposed value was not accepted, you see the same value repeated again. If you notice a straight line, this is an indication that several proposed values are being rejected. This is a sign that something is askew with the distribution or sampling process.\n",
    "\n",
    "\n",
    "#### Building the Inferred Distribution\n",
    "\n",
    "Use the current values that we obtain at each step and build a frequency distribution (histogram) from it.\n",
    "\n",
    "#### Representing the Inferred Distribution\n",
    "\n",
    "* Compute the mean values of the saved parameters\n",
    "* Compute the standard deviation and variance of the saved parameters\n",
    "* Compute the minimum and maximum values of the saved parameters\n",
    "* Compute the quantiles of the saved parameters\n",
    "* If required, express it as the parameters of a canonical distribution if it is known that the inferred distribution will be of a certain form.\n",
    "\n",
    "\n",
    "#### Notes about the Metropolis algorithm\n",
    "\n",
    "* The proposal distribution has to be symmetric, this condition is relaxed in the Metropolis-Hastings algorithm. A normal distribution is commonly used as a proposal distribution in the Metropolis algorithm.\n",
    "\n",
    "* The choice of a prior distribution influences the performance of this algorithm.\n",
    "\n",
    "* Tuning - A hyperparameter, i.e. the standard deviation is essential to tune this proposal distribution. This needs to be tuned such that the acceptance probability is a certain value. This is referred to as the tuning parameter.\n"
   ]
  },
  {
   "source": [
    "#### Python Code for walkthrough of algorithm\n",
    "\n",
    "Using the example above and the shark attack problem, run a simulation for 1000 iterations\n",
    "\n",
    "#### Summarize the above distribution - Mean, Variance, Minimum and Maximum, Quartiles\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### The Metropolis-Hastings Algorithm\n",
    "\n",
    "#### Overview\n",
    "\n",
    "One of the limitations of the Metropolis algorithm was the requirement of a symmetric proposal distribution. The Metropolis-Hastings relaxes this requirement by providing a correction term if a non-symmetric proposal distribution is used. This correction is applied to $p_{move}$ and is of the form\n",
    "\n",
    "$p_{move} = min( \\dfrac{P(\\mu_{proposed} | data) \\cdot g(\\mu_{current} | \\mu_{proposed})}{P(\\mu_{current} | data) \\cdot g(\\mu_{proposed} | \\mu_{current})}, 1)$\n",
    "\n",
    "where the correction term is \n",
    "\n",
    "$\\dfrac{g(\\mu_{current} | \\mu_{proposed})}{g(\\mu_{proposed} | \\mu_{current})}$\n",
    "\n",
    "The term $g(\\mu_{current} | \\mu_{proposed})$ is the probability density of drawing $\\mu_{current}$ from a normal distribution centered around $\\mu_{proposed}$. The standard deviation for this normal distribution is the tuning parameter. For a symmetric proposal distribution such as a normal distribution the correction term would be 1 since the probability density of drawing $\\mu_{current}$ from a Gaussian centered at $\\mu_{proposal}$ only depends on the distance between $\\mu_{current}$ and $\\mu_{proposal}$ (standard deviation is a hyperparameter that is fixed). Similarly, the probability density of drawing $\\mu_{proposal}$ from a Gaussian centered around $\\mu_{current}$ depends only on the distance between these two values, which is the same as before. Hence the numerator and the denominator are the same which results in the correction factor being 1.\n",
    "\n",
    "#### Why do we need a correction term?\n",
    "\n",
    "The correction term exists to account for the lack of symmetry in a non-symmetric proposal distribution. The Metropolis algorithm is therefore a specific case of the Metropolis-Hastings algorithm. When distributions other than a Gaussian is used as a proposed distribution, one can center $\\mu_{current}$ and  $\\mu_{proposal}$ on the mean, median or mode of the distribution. It is also possible to draw samples from a fixed distribution, this technique is called the Independent Metropolis-Hastings sampling algorithm.\n",
    "\n",
    "#### What is the advantage of using a non-symmetric proposal distribution?\n",
    "\n",
    "If the parameter we are seeking is bounded in value, using a symmetric dsitribution can result in invalid draws. Also, since we are working in a Bayesian setting we want to take advantage of our prior knowledge of this parameter. If it known that the parameter has a certain distribution, we should be able to incorporate this information into our sampling process.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamiltonian Monte Carlo (also called Hybrid Monte Carlo)\n",
    "\n",
    "Based on the solution of differential equations known as Hamilton's equations. These differential equations depend on the probability distributions we are trying to learn. We navigate these distributions by moving around them in a trajectory using steps that are defined by a position and momentum at that position. Navigating these trajectories can be a very expensive process and the goal is to minimize this computational process.\n",
    "\n",
    "HMC is based on the notion of conservation of energy. When the sampler trajectory is far away from the probability mass center, it has high potential energy but low kinetic energy and when it is closer to the center of the probability mass will have high kinetic energy but low potential energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}